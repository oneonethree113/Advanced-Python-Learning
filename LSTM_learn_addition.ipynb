{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsnqWBiIV6yaTls1jejPeM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oneonethree113/Advanced-Python-Learning/blob/main/LSTM_learn_addition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M8o12_PDp2HP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "\n",
        "# Define the LSTM model\n",
        "class LSTMAdditionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LSTMAdditionModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        output = self.linear(lstm_out)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "ji9B_pnUwqOa"
      },
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def generate_output_data(input_data):\n",
        "    output_data = []\n",
        "\n",
        "    for sample in input_data:\n",
        "      cumulative_sum = 0.0\n",
        "      sample_output_data=[]\n",
        "      for value in sample:\n",
        "\n",
        "        cumulative_sum += value[0]\n",
        "        sample_output_data.append([cumulative_sum])\n",
        "      output_data.append(sample_output_data)\n",
        "\n",
        "    return torch.tensor(output_data)\n",
        "\n",
        "random.seed(42)\n",
        "# Create sample input data\n",
        "input_data =([[[3], [0.1], [0.3]],\n",
        "                           [[0.2], [0.3], [0.4]],\n",
        "                           [[0.3], [0.4], [0.5]],\n",
        "                           [[1.3], [0.4], [0.5]]])\n",
        "input_data= [ ([[random.uniform(-10, 10)] for _ in range(3)] )  for _ in range(1000) ]\n",
        "# Generate output data\n",
        "output_data = generate_output_data(input_data)\n",
        "print(\"Generated Input Data:\")\n",
        "print(input_data[0])\n",
        "print(\"Generated Output Data:\")\n",
        "print(output_data[0])\n",
        "input_data=torch.tensor(input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4CwX-Md6iu3",
        "outputId": "a87d24d4-d2ac-4fb9-e747-87fa95c50513"
      },
      "execution_count": 485,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Input Data:\n",
            "[[2.7885359691576745], [-9.49978489554666], [-4.499413632617615]]\n",
            "Generated Output Data:\n",
            "tensor([[  2.7885],\n",
            "        [ -6.7112],\n",
            "        [-11.2107]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.manual_seed(1)\n",
        "# Define hyperparameters\n",
        "input_size = 1\n",
        "hidden_size = 1\n",
        "output_size = 1\n",
        "batch_size = 3  # Number of samples in each batch\n",
        "num_epochs = 10000\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Initialize the model\n",
        "AdditionModel = LSTMAdditionModel(input_size, hidden_size, output_size)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(AdditionModel.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = AdditionModel(input_data)\n",
        "    loss = criterion(outputs, output_data)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 500 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5cv0lxO7gno",
        "outputId": "36544000-ae20-4fbf-be33-94ac6d729c7d"
      },
      "execution_count": 488,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [500/10000], Loss: 20.8938\n",
            "Epoch [1000/10000], Loss: 8.5162\n",
            "Epoch [1500/10000], Loss: 4.7065\n",
            "Epoch [2000/10000], Loss: 3.0729\n",
            "Epoch [2500/10000], Loss: 2.1939\n",
            "Epoch [3000/10000], Loss: 1.6498\n",
            "Epoch [3500/10000], Loss: 1.2819\n",
            "Epoch [4000/10000], Loss: 1.0183\n",
            "Epoch [4500/10000], Loss: 0.8218\n",
            "Epoch [5000/10000], Loss: 0.6710\n",
            "Epoch [5500/10000], Loss: 0.5526\n",
            "Epoch [6000/10000], Loss: 0.4583\n",
            "Epoch [6500/10000], Loss: 0.3823\n",
            "Epoch [7000/10000], Loss: 0.3204\n",
            "Epoch [7500/10000], Loss: 0.2696\n",
            "Epoch [8000/10000], Loss: 0.3610\n",
            "Epoch [8500/10000], Loss: 0.2575\n",
            "Epoch [9000/10000], Loss: 0.1649\n",
            "Epoch [9500/10000], Loss: 0.2501\n",
            "Epoch [10000/10000], Loss: 0.1239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good, It can do a list of addition"
      ],
      "metadata": {
        "id": "dVc8cgjPlkS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data=[0.2,0.1,0.7,0.1]\n",
        "test_data=[[[i] for i in test_data]]\n",
        "testPredict_data = generate_output_data(test_data)\n",
        "print(\"Generated Input Data:\")\n",
        "print(test_data)\n",
        "print(\"Generated Output Data:\")\n",
        "print(testPredict_data)\n",
        "AdditionModel(torch.tensor(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkcVFnTZkcM6",
        "outputId": "babb4aaa-4b82-401c-d7f8-9dcb71ae79ba"
      },
      "execution_count": 489,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Input Data:\n",
            "[[[0.2], [0.1], [0.7], [0.1]]]\n",
            "Generated Output Data:\n",
            "tensor([[[0.2000],\n",
            "         [0.3000],\n",
            "         [1.0000],\n",
            "         [1.1000]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.2192],\n",
              "         [0.2990],\n",
              "         [1.0185],\n",
              "         [1.1104]]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 489
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why can't LSTM do looping?!"
      ],
      "metadata": {
        "id": "vdBDWw0vlj4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size,max_length):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size,2, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, output_size)\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def forward(self, input_tuple):\n",
        "        lstm_input = input_tuple.unsqueeze(0).repeat(max_length, 1, 1)\n",
        "        #print(lstm_input)\n",
        "        lstm_out, _ = self.lstm(lstm_input)\n",
        "        output = self.linear(lstm_out)\n",
        "        return output\n",
        "def generate_output_data_multtoadd(input_data,length):\n",
        "    output_data = []\n",
        "\n",
        "    for sample in input_data:\n",
        "      #sample_output_data=[sample[1] if i<sample[0] else 0.0 for i in range(length)]\n",
        "      sample_output_data=[[sample[1] ] if i<sample[0] else [0] for i in range(length)]\n",
        "      output_data.append(sample_output_data)\n",
        "      print(sample, sample_output_data)\n",
        "    return torch.tensor(output_data)\n",
        "# Define hyperparameters\n",
        "input_size = 2\n",
        "hidden_size = 20\n",
        "output_size = 1\n",
        "max_length = 1\n",
        "# Create sample input data\n",
        "input_data = [(2.0, 2.0),(3.0, 1.0),(1.0, 3.0)]\n",
        "input_data=[(float(random.randint(0, max_length)),float(random.randint(1, 10))) for _ in range(20 )]\n",
        "# Initialize the model\n",
        "model = LSTMModel(input_size, hidden_size, output_size,max_length)\n",
        "\n",
        "# Test the model\n",
        "for input_tuple in input_data:\n",
        "    input_tuple = (torch.tensor([input_tuple[0],input_tuple[1]]))\n",
        "    with torch.no_grad():\n",
        "        predicted_output = model(input_tuple)\n",
        "\n",
        "output_data=generate_output_data_multtoadd(input_data,max_length)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APxdlZD3BkpC",
        "outputId": "07cb8f40-ef6e-4985-b42b-70422c3ed9e5"
      },
      "execution_count": 506,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.0, 3.0) [[0]]\n",
            "(1.0, 6.0) [[6.0]]\n",
            "(0.0, 2.0) [[0]]\n",
            "(1.0, 9.0) [[9.0]]\n",
            "(1.0, 9.0) [[9.0]]\n",
            "(1.0, 5.0) [[5.0]]\n",
            "(1.0, 1.0) [[1.0]]\n",
            "(1.0, 2.0) [[2.0]]\n",
            "(1.0, 3.0) [[3.0]]\n",
            "(0.0, 10.0) [[0]]\n",
            "(0.0, 2.0) [[0]]\n",
            "(0.0, 5.0) [[0]]\n",
            "(1.0, 7.0) [[7.0]]\n",
            "(1.0, 7.0) [[7.0]]\n",
            "(1.0, 10.0) [[10.0]]\n",
            "(1.0, 1.0) [[1.0]]\n",
            "(0.0, 5.0) [[0]]\n",
            "(1.0, 3.0) [[3.0]]\n",
            "(1.0, 1.0) [[1.0]]\n",
            "(1.0, 6.0) [[6.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=300\n",
        "learning_rate=0.001\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for i, input_tuple in enumerate(input_data):\n",
        "        input_tuple = (torch.tensor([input_tuple[0],input_tuple[1]]))\n",
        "        target = torch.tensor(output_data[i])\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_tuple)\n",
        "        loss = criterion(outputs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}')\n",
        "input_tuple=input_data[0]\n",
        "print(input_tuple)\n",
        "print(\"Predicted Output:\")\n",
        "print(model((torch.tensor([input_tuple[0],input_tuple[1]]))))\n",
        "print(\"True Output:\")\n",
        "print(output_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNHo_K0oK2Ol",
        "outputId": "e54968ab-b2be-4b83-fd5e-e64f7f2f30ab"
      },
      "execution_count": 509,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-509-1e2763ae49fc>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  target = torch.tensor(output_data[i])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/300], Loss: 0.0093\n",
            "Epoch [200/300], Loss: 0.0033\n",
            "Epoch [300/300], Loss: 0.0031\n",
            "(0.0, 3.0)\n",
            "Predicted Output:\n",
            "tensor([[[0.0270]]], grad_fn=<ViewBackward0>)\n",
            "True Output:\n",
            "tensor([[0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define hyperparameters\n",
        "input_size = 2\n",
        "hidden_size = 20\n",
        "output_size = 1\n",
        "max_length = 2\n",
        "# Create sample input data\n",
        "input_data = [(2.0, 2.0),(3.0, 1.0),(1.0, 3.0)]\n",
        "input_data=[(float(random.randint(0, max_length)),float(random.randint(1, 10))) for _ in range(20 )]\n",
        "\n",
        "# Test the model\n",
        "for input_tuple in input_data:\n",
        "    input_tuple = (torch.tensor([input_tuple[0],input_tuple[1]]))\n",
        "    with torch.no_grad():\n",
        "        predicted_output = model(input_tuple)\n",
        "\n",
        "output_data=generate_output_data_multtoadd(input_data,max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW99AnOMpLB1",
        "outputId": "b8afdc8f-3695-4acc-dea9-8ad2796fd450"
      },
      "execution_count": 510,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2.0, 4.0) [[4.0], [4.0]]\n",
            "(0.0, 8.0) [[0], [0]]\n",
            "(1.0, 6.0) [[6.0], [0]]\n",
            "(0.0, 6.0) [[0], [0]]\n",
            "(1.0, 5.0) [[5.0], [0]]\n",
            "(1.0, 8.0) [[8.0], [0]]\n",
            "(2.0, 2.0) [[2.0], [2.0]]\n",
            "(0.0, 3.0) [[0], [0]]\n",
            "(1.0, 8.0) [[8.0], [0]]\n",
            "(1.0, 5.0) [[5.0], [0]]\n",
            "(2.0, 7.0) [[7.0], [7.0]]\n",
            "(2.0, 2.0) [[2.0], [2.0]]\n",
            "(0.0, 8.0) [[0], [0]]\n",
            "(0.0, 7.0) [[0], [0]]\n",
            "(2.0, 8.0) [[8.0], [8.0]]\n",
            "(2.0, 6.0) [[6.0], [6.0]]\n",
            "(0.0, 9.0) [[0], [0]]\n",
            "(0.0, 2.0) [[0], [0]]\n",
            "(1.0, 9.0) [[9.0], [0]]\n",
            "(1.0, 3.0) [[3.0], [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=1000\n",
        "learning_rate=0.0001\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for i, input_tuple in enumerate(input_data):\n",
        "        input_tuple = (torch.tensor([input_tuple[0],input_tuple[1]]))\n",
        "        target = torch.tensor(output_data[i])\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_tuple)\n",
        "        loss = criterion(outputs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}')\n",
        "input_tuple=input_data[0]\n",
        "print(input_tuple)\n",
        "print(\"Predicted Output:\")\n",
        "print(model((torch.tensor([input_tuple[0],input_tuple[1]]))))\n",
        "print(\"True Output:\")\n",
        "print(output_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--4NxpaepTnG",
        "outputId": "049a7aca-3c91-47af-acfc-38ba25754405"
      },
      "execution_count": 512,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-512-6b7c2fa7988a>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  target = torch.tensor(output_data[i])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/300], Loss: 76.0786\n",
            "Epoch [200/300], Loss: 76.0393\n",
            "Epoch [300/300], Loss: 76.0237\n",
            "(2.0, 4.0)\n",
            "Predicted Output:\n",
            "tensor([[[3.9220]],\n",
            "\n",
            "        [[3.9220]]], grad_fn=<ViewBackward0>)\n",
            "True Output:\n",
            "tensor([[4.],\n",
            "        [4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=4\n",
        "\n",
        "input_tuple=input_data[i]\n",
        "print(input_tuple)\n",
        "print(\"Predicted Output:\")\n",
        "print(model((torch.tensor([input_tuple[0],input_tuple[1]]))))\n",
        "print(\"True Output:\")\n",
        "print(output_data[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55_v9LT1MrwA",
        "outputId": "085b9aae-7cfb-4414-fb0a-b3003b8ac835"
      },
      "execution_count": 505,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1.0, 9.0)\n",
            "Predicted Output:\n",
            "tensor([[[4.4510]],\n",
            "\n",
            "        [[4.4510]]], grad_fn=<ViewBackward0>)\n",
            "True Output:\n",
            "tensor([[9.],\n",
            "        [0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tuple=(20.0,20.0)\n",
        "print(input_tuple)\n",
        "print(\"Predicted Output:\")\n",
        "print(model((torch.tensor([input_tuple[0],input_tuple[1]]))))\n",
        "print(\"True Output:\")\n",
        "print(input_tuple[1]*input_tuple[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tZLUCpmZzDz",
        "outputId": "c923a4c4-c7a7-411b-af83-54b84c5d1729"
      },
      "execution_count": 434,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20.0, 20.0)\n",
            "Predicted Output:\n",
            "tensor([[[3.7709]],\n",
            "\n",
            "        [[3.7709]],\n",
            "\n",
            "        [[3.7709]]], grad_fn=<ViewBackward0>)\n",
            "True Output:\n",
            "400.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8yrdJaGpbDUw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}